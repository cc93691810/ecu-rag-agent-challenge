import re
from langchain_core.documents import Document

def load_docs_from_markdown(file_path: str) -> list[Document]:
    with open(file_path, encoding="utf-8") as f:
        content = f.read()
    # æå– Series åç§°ï¼ˆä»æ–‡ä»¶åæ¨æ–­ï¼‰
    if "700" in file_path:
        series_name = "ECU-700"
    elif "800" and "base" in file_path.lower():
        series_name = "ECU-800B"
    elif "800" and "plus" in file_path.lower():
        series_name = "ECU-800P"
    else:
        series_name = "Unknown"
    
    docs = []
    sections = re.split(r'\n##\s+(.+)', content)    

    for i in range(1, len(sections), 2):
        title = sections[i].strip()
        body = sections[i + 1].strip() if i + 1 < len(sections) else ""
        if not title or "series" in title.lower():
            continue
        ## åŠ å…¥è¡¨æ ¼é€»è¾‘ç»†åˆ†
        if "|" in body and "**" in body:
            # å°è¯•æå–è¡¨æ ¼éƒ¨åˆ†
            table_lines = []
            non_table_lines = []
            in_table = False
            for line in body.split("\n"):
                stripped = line.strip()
                if stripped.startswith("|") and stripped.endswith("|"):
                    table_lines.append(stripped)
                    in_table = True
                else:
                    if in_table and (stripped == "" or all(c in "-| " for c in stripped)):
                        # è·³è¿‡è¡¨æ ¼åˆ†éš”çº¿ï¼ˆå¦‚ |---|---|)
                        continue                    
                    non_table_lines.append(line)
                    in_table = False  # éè¡¨æ ¼å†…å®¹é‡ç½®çŠ¶æ€
            # === 1. å¤„ç†è¡¨æ ¼è¡Œï¼šæ¯è¡Œä¸€ä¸ª chunk ===
            if table_lines:
                # è¿‡æ»¤æ‰è¡¨å¤´åˆ†éš”è¡Œï¼ˆé€šå¸¸å« ---ï¼‰
                data_rows = [
                    row for row in table_lines
                    if not re.match(r'\|\s*:?-{2,}:?\s*(\|\s*:?-{2,}:?\s*)*\|', row)
                ]
                # è·³è¿‡è¡¨å¤´ï¼ˆç¬¬ä¸€è¡Œï¼‰
                for row in data_rows[1:]:
                    cells = [cell.strip().replace("**", "").strip() for cell in row.split("|")[1:-1]]
                    if len(cells) >= 2:
                        param_name = cells[0]
                        param_value = cells[1]
                        if param_name and param_value:
                            text = f"Series:{series_name}\nModel:{title}\nParameter:{param_name}\nValue:{param_value}"
                            docs.append(Document(
                                page_content=text,
                                metadata={
                                    "source": file_path,
                                    "model": title,
                                    "parameter": param_name
                                }
                            ))
            # === 2. ä¿ç•™éè¡¨æ ¼æè¿°ï¼ˆå¦‚è½¯ä»¶é…ç½®ï¼‰ä½œä¸ºå•ç‹¬ chunk ===
            non_table_body = "\n".join(non_table_lines).strip()
            if non_table_body:
                text = f"Series: {series_name}\nModel: {title}\n\n{non_table_body}"
                docs.append(Document(
                    page_content=text,
                    metadata={"source": file_path, "model": title}
                ))
        else:
            # æ— è¡¨æ ¼ï¼šä¿ç•™åŸå§‹æ•´å— chunkï¼ˆå…¼å®¹ ECU-700ï¼‰
            text = f"Series: {series_name}\nModel: {title}\n\n{body}"
            docs.append(Document(
                page_content=text,
                metadata={"source": file_path, "model": title}
            ))        
    return docs

## test
# from pathlib import Path
# import os
# current_file = Path(__file__).resolve()  # rag.py çš„ç»å¯¹è·¯å¾„
# project_root = current_file.parent.parent  # é¡¹ç›®æ ¹ç›®å½•

# # åŠ è½½æ–‡æ¡£
# data_dir = project_root / "data"
# file_map = {
#     "700": data_dir / "ECU-700_Series_Manual.md",
#     "800B": data_dir / "ECU-800_Series_Base.md",
#     "800P": data_dir / "ECU-800_Series_Plus.md"
# }

# test_series = "800P"  # å¯ä»¥æ”¹ä¸º "700", "800B", "800P"
# if test_series in file_map:
#     file_path = str(file_map[test_series])
#     if os.path.exists(file_path):
#         print(f"\nğŸ” å¼€å§‹æµ‹è¯• {test_series} ç³»åˆ—:")
#         print(f"æ–‡ä»¶è·¯å¾„: {file_path}")
#         docs = load_docs_from_markdown(file_path)
        
#         # å¯é€‰ï¼šæŸ¥çœ‹ç‰¹å®šæ–‡æ¡£çš„å®Œæ•´å†…å®¹
#         if docs:
#             print(f"\n{'='*80}")
#             print(f"ğŸ” æŸ¥çœ‹æ–‡æ¡£çš„å®Œæ•´å†…å®¹:")
#             print(f"{'='*80}")
#             for i in range(len(docs)):
#                 print(f"\nğŸ“„ æ–‡æ¡£ {i+1}/{len(docs)}:")
#                 print(f"å…ƒæ•°æ®: {docs[i].metadata}")
#                 print(f"å†…å®¹:")
#                 print(f"{'-'*60}")
#                 print(docs[i].page_content)
#                 print(f"{'-'*60}")
#                 print(f"é•¿åº¦: {len(docs[i].page_content)} å­—ç¬¦\n")
#     else:
#         print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
# else:
#     print(f"âŒ æ— æ•ˆçš„ç³»åˆ—æ ‡è¯†: {test_series}")
#     print(f"å¯ç”¨çš„ç³»åˆ—: {list(file_map.keys())}")
